S# SynthEval: Automated Code Review Dataset Generator with Human Validation

![SynthEval Banner](https://your-banner-url.png)

## ğŸš€ Overview
SynthEval is an innovative platform that combines synthetic code review generation with human validation to create high-quality datasets for code review analysis. The project leverages LLMs (GPT-3.5/CodeLlama) to generate code reviews and implements a robust validation system with expert developers.

### Key Features
- ğŸ¤– Automated code review generation using state-of-the-art LLMs
- ğŸ‘¥ Human validation interface for quality assessment
- ğŸ“Š Comprehensive metrics and analytics
- ğŸ”„ Integration with GitHub for real code samples
- âš¡ Real-time validation scoring system

## ğŸ› ï¸ Tech Stack
- **Backend**: FastAPI, Python
- **Frontend**: React, TailwindCSS
- **Database**: PostgreSQL
- **ML Models**: GPT-3.5/CodeLlama
- **Infrastructure**: Docker

## ğŸ—ï¸ Architecture

syntheval/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # Pydantic models
â”‚   â”‚   â”œâ”€â”€ routers/         # API endpoints
â”‚   â”‚   â””â”€â”€ services/        # Business logic
â”‚   â””â”€â”€ tests/               # Unit tests
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/      # React components
    â”‚   â”œâ”€â”€ pages/           # Page layouts
    â”‚   â””â”€â”€ services/        # API integration
    â””â”€â”€ tests/               # Frontend tests

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Node.js 14+
- Docker
- GitHub API Token
- OpenAI API Key

### Installation
1. Clone the repository:
```bash
git clone https://github.com/yourusername/syntheval.git
cd syntheval
2. Set up environment variables:
cp .env.example .env
# Add your GitHub and OpenAI API tokens to .env
3. Start the application:
docker-compose up
The application will be available at:

Frontend: http://localhost:3000
Backend API: http://localhost:8000
API Docs: http://localhost:8000/docs

